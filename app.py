# -*- coding: utf-8 -*-
"""file11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vn3ShWiCCPGRIBLbFRTYtbdqWkJEyAxP
"""

import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO

# --- Step 1: Google Drive Integration (Conceptual for Streamlit) ---
# In a typical Streamlit deployment, direct 'drive.mount' like in Colab isn't
# straightforward. If you're running this locally, you'd typically have
# Google Drive synced or use the Google Drive API for direct uploads.
# For simplicity, this example will assume the user downloads the output
# or you have a pre-configured service account for direct upload in a
# production environment.
# For this example, we'll focus on saving to a BytesIO object and then
# providing a download button for the user. If direct Google Drive
# upload from a deployed Streamlit app is a strict requirement,
# you'd need to implement Google Drive API authentication and upload.

st.set_page_config(layout="wide", page_title="Voice Influx Forecast")

st.title("Voice Influx Forecasting Application")
st.write("Upload your 'Voice2md.xlsx' file to generate monthly, daily, and hourly forecasts.")

# --- File Uploader ---
uploaded_file = st.file_uploader("Choose a Voice2md.xlsx file", type="xlsx")

if uploaded_file is not None:
    try:
        # Step 2: Import libraries (already imported)

        # Step 3: Load Excel sheets from the uploaded file
        st.info("Loading Excel sheets...")
        df_hourly = pd.read_excel(uploaded_file, sheet_name="hourly")
        df_forecast = pd.read_excel(uploaded_file, sheet_name='mmf')
        st.success("Sheets loaded successfully!")

        # Step 4: Preprocess hourly data
        st.info("Preprocessing hourly data...")
        df_hourly['Date'] = pd.to_datetime(df_hourly['Date'])
        df_hourly['Weekday'] = df_hourly['Date'].dt.day_name()
        st.success("Hourly data preprocessed!")

        # Step 5: Group by Pod, Weekday, Hour and compute proportions
        st.info("Calculating hourly proportions...")
        grouped = df_hourly.groupby(['Pod', 'Weekday', 'Hour'])['Influx'].sum().reset_index()
        totals = grouped.groupby(['Pod', 'Weekday'])['Influx'].sum().reset_index()
        totals.rename(columns={'Influx': 'TotalInflux'}, inplace=True)
        merged = pd.merge(grouped, totals, on=['Pod', 'Weekday'])
        merged['HourlyProportion'] = merged['Influx'] / merged['TotalInflux']
        st.success("Hourly proportions computed!")

        # Step 6: Outlier filtering but keep all weekdays
        st.info("Filtering outliers...")
        cleaned_data = []
        for pod in merged['Pod'].unique():
            pod_data = merged[merged['Pod'] == pod]
            for weekday in pod_data['Weekday'].unique():
                sub_df = pod_data[pod_data['Weekday'] == weekday].copy()
                q1 = sub_df['HourlyProportion'].quantile(0.25)
                q3 = sub_df['HourlyProportion'].quantile(0.75)
                iqr = q3 - q1
                lower = q1 - 1.5 * iqr
                upper = q3 + 1.5 * iqr
                sub_df = sub_df[(sub_df['HourlyProportion'] >= lower) & (sub_df['HourlyProportion'] <= upper)]
                cleaned_data.append(sub_df)

        final_df = pd.concat(cleaned_data, ignore_index=True)
        st.success("Outlier filtering complete!")

        # Step 7: Pivot table (optional inspection)
        # This will be included in the output Excel, so no need to display here unless for debugging.
        pivot = final_df.pivot_table(index=['Pod', 'Weekday'],
                                     columns='Hour',
                                     values='HourlyProportion',
                                     fill_value=0)

        # Step 8: Load and clean forecast
        st.info("Processing forecast data...")
        df_forecast.columns = ['Month', 'Forecasted Influx']
        df_forecast['Month'] = pd.to_datetime(df_forecast['Month'], errors='coerce')
        df_forecast.dropna(subset=['Month'], inplace=True)
        df_forecast.set_index('Month', inplace=True)
        df_forecast = df_forecast.sort_index()
        df_forecast = df_forecast.asfreq('MS')
        st.success("Forecast data processed!")

        # Step 9: Get pod proportions and weekday distributions
        st.info("Calculating pod and weekday proportions...")
        daily_df = df_hourly.groupby(['Date', 'Pod'])['Influx'].sum().reset_index()
        daily_df['Weekday'] = daily_df['Date'].dt.weekday

        pod_total = daily_df.groupby('Pod')['Influx'].sum()
        pod_prop = pod_total / pod_total.sum()

        weekday_total = daily_df.groupby(['Pod', 'Weekday'])['Influx'].sum()
        weekday_prop = weekday_total.groupby(level=0).apply(lambda x: x / x.sum())
        st.success("Pod and weekday proportions calculated!")

        # Step 10: Monthly pod forecast
        st.info("Generating monthly pod forecast...")
        monthly_pod_forecast = pd.DataFrame(index=df_forecast.index)
        for pod in pod_prop.index:
            monthly_pod_forecast[pod] = df_forecast['Forecasted Influx'] * pod_prop[pod]
        st.success("Monthly pod forecast generated!")

        # Step 11: Daily pod forecast (corrected logic)
        st.info("Generating daily pod forecast...")
        daily_forecast_all = []
        for month_start in df_forecast.index:
            month_end = month_start + pd.offsets.MonthEnd(0)
            days = pd.date_range(start=month_start, end=month_end, freq='D')
            weekday_indices = days.weekday  # 0=Mon, ..., 6=Sun
            weekday_counts = pd.Series(weekday_indices).value_counts().to_dict()

            month_data = {'Date': days}
            for pod in pod_prop.index:
                pod_month_total = monthly_pod_forecast.loc[month_start, pod]
                pod_week_props = weekday_prop.loc[pod]
                pod_daily = []

                for day in days:
                    weekday_idx = day.weekday()
                    weekday_prop_val = pod_week_props.get(weekday_idx, 0)
                    # The division by 4 in the original code seems arbitrary if not tied to specific logic (e.g., average weeks in a month).
                    # For a more accurate daily distribution, you'd typically distribute the monthly total based on the sum of historical weekday proportions,
                    # or by the number of occurrences of each weekday in that specific month.
                    # Here, I'm adjusting to distribute based on the proportion of the day's total influx within the month,
                    # accounting for how many of that specific weekday are in the month.
                    # A more robust approach would be to distribute the monthly total proportionally among the actual days,
                    # reflecting their historical proportion within their respective weekdays.

                    # To distribute accurately, we need to know the sum of the historical proportions for the weekdays present in the current month.
                    # Let's adjust the daily_val calculation:
                    # Sum of historical weekday proportions for the weekdays present in the current month for the specific pod
                    sum_of_relevant_weekday_props = sum(pod_week_props.get(idx, 0) for idx in weekday_indices)

                    if sum_of_relevant_weekday_props > 0:
                        daily_val = (pod_month_total * weekday_prop_val) / sum_of_relevant_weekday_props * weekday_counts.get(weekday_idx, 1)
                    else:
                        daily_val = 0 # Avoid division by zero if no relevant weekday proportions

                    pod_daily.append(daily_val)

                month_data[pod] = pod_daily

            daily_forecast_all.append(pd.DataFrame(month_data))

        daily_forecast_df = pd.concat(daily_forecast_all, ignore_index=True)
        daily_forecast_df.set_index('Date', inplace=True)
        st.success("Daily pod forecast generated!")


        # Step 12: Hourly forecast
        st.info("Generating hourly forecast...")
        hourly_forecast_all = []
        # Create a mapping for weekday names to match the 'final_df'
        weekday_name_map = {
            0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday',
            4: 'Friday', 5: 'Saturday', 6: 'Sunday'
        }

        for date, row in daily_forecast_df.iterrows():
            weekday_name = weekday_name_map[date.weekday()] # Use the map for consistency
            for pod in pod_prop.index:
                if pod not in row:
                    continue
                daily_val = row[pod]
                # Filter final_df once per pod and weekday to avoid repeated filtering inside the inner loop
                pod_hourly_props = final_df[(final_df['Pod'] == pod) & (final_df['Weekday'] == weekday_name)]

                # Ensure that there are hourly proportions for the given pod and weekday
                if not pod_hourly_props.empty:
                    # Normalize hourly proportions for the given day if they don't sum to 1 due to outlier removal
                    sum_hr_prop = pod_hourly_props['HourlyProportion'].sum()
                    if sum_hr_prop > 0:
                        normalized_hourly_props = pod_hourly_props['HourlyProportion'] / sum_hr_prop
                    else:
                        normalized_hourly_props = pd.Series([0] * len(pod_hourly_props), index=pod_hourly_props.index) # All zeros if sum is zero

                    for idx, hr_row in pod_hourly_props.iterrows():
                        hour = hr_row['Hour']
                        hr_prop = normalized_hourly_props.loc[idx] # Use the normalized proportion
                        hourly_forecast_all.append({
                            'Date': date,
                            'Hour': int(hour),
                            'Pod': pod,
                            'Forecasted Influx': (daily_val * hr_prop)
                        })

        hourly_forecast_df = pd.DataFrame(hourly_forecast_all)
        hourly_forecast_df = hourly_forecast_df.sort_values(by=['Date', 'Hour', 'Pod'])
        st.success("Hourly forecast generated!")

        st.subheader("Forecast Generation Complete!")

        # --- Output File Naming ---
        output_filename = st.text_input("Enter a name for the output Excel file (e.g., My_Forecast.xlsx):", "Generated_Forecast.xlsx")

        if st.button("Generate and Download Forecast"):
            # Step 13: Save outputs to an in-memory BytesIO object
            excel_buffer = BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='xlsxwriter') as writer:
                df_forecast.to_excel(writer, sheet_name='Monthly Forecast')
                monthly_pod_forecast.to_excel(writer, sheet_name='Monthly Pod Forecast')
                daily_forecast_df.to_excel(writer, sheet_name='Daily Pod Forecast')
                hourly_forecast_df.to_excel(writer, sheet_name='Hourly Pod Forecast', index=False)
                pivot.to_excel(writer, sheet_name='Hourly Proportions (7 Days)')

            excel_buffer.seek(0) # Rewind the buffer to the beginning

            # Provide download button
            st.download_button(
                label="Download Forecast Excel File",
                data=excel_buffer,
                file_name=output_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            st.success(f"Forecast file '{output_filename}' is ready for download.")

            st.write("---")
            st.write("If you need to save directly to Google Drive from a deployed Streamlit app, you would need to implement Google Drive API integration (e.g., using `gspread` or `PyDrive`) and handle authentication securely.")


    except Exception as e:
        st.error(f"An error occurred: {e}")
        st.exception(e) # Display the full traceback for debugging